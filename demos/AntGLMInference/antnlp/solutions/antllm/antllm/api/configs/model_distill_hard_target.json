{
	"train_config": {
		"output_dir": "./output",
		"do_train": true,
		"do_eval": false,
		"evaluation_strategy": "epoch",
		"save_strategy": "epoch",
		"load_best_model_at_end": true,
		"seed": 42,
		"per_device_train_batch_size": 1,
		"per_device_eval_batch_size": 1,
		"gradient_accumulation_steps": 1,
		"num_train_epochs": 2,
		"logging_first_step": true,
		"dataloader_num_workers": 4,
		"dataloader_drop_last": false,
		"logging_steps": 30,
		"overwrite_output_dir": true,
		"warmup_steps": 2000,
		"learning_rate": 1e-5,
		"weight_decay": 0.01,
		"lr_scheduler_type": "cosine",
		"save_total_limit": 10,
		"adam_beta1": 0.9,
		"adam_beta2": 0.999,
		"adam_epsilon": 1e-8,
		"fp16": true,
		"predict_with_generate": true,
		"metric_for_best_model": "BLEU",
		"greater_is_better": true
	},
	"metric": "bleu",
	"small_model_ft": true,
	"data_config": {
		"max_source_length": 500,
		"max_target_length": 32,
		"preprocessing_num_workers": 4,
		"input_key": "input",
		"output_key": "output"
	},
	"trainer_type": "Seq2SeqTrainer",
	"teacher_fine_tune": {
		"fine_tuned_path": "./fine_tuned_teacher",
		"do_fine_tune": false
	},
    "teacher_predict_config": {
        "max_output_length": 120
    }
}